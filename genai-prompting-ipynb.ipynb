{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T02:43:44.071779Z","iopub.execute_input":"2025-04-01T02:43:44.072353Z","iopub.status.idle":"2025-04-01T02:43:53.504642Z","shell.execute_reply.started":"2025-04-01T02:43:44.072295Z","shell.execute_reply":"2025-04-01T02:43:53.503313Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T02:44:24.468671Z","iopub.execute_input":"2025-04-01T02:44:24.469102Z","iopub.status.idle":"2025-04-01T02:44:26.203272Z","shell.execute_reply.started":"2025-04-01T02:44:24.469066Z","shell.execute_reply":"2025-04-01T02:44:26.202079Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from google.api_core import retry\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T02:45:02.946109Z","iopub.execute_input":"2025-04-01T02:45:02.946669Z","iopub.status.idle":"2025-04-01T02:45:02.953425Z","shell.execute_reply.started":"2025-04-01T02:45:02.946640Z","shell.execute_reply":"2025-04-01T02:45:02.952109Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T02:58:55.257893Z","iopub.execute_input":"2025-04-01T02:58:55.258332Z","iopub.status.idle":"2025-04-01T02:58:55.406292Z","shell.execute_reply.started":"2025-04-01T02:58:55.258307Z","shell.execute_reply":"2025-04-01T02:58:55.405272Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import google.generativeai as genai\n\n#GOOGLE_API_KEY = \"ac42ee40666179039c3f0111253ca401\"\nGOOGLE_API_KEY = \"AIzaSyCKjXU-rGdoKM1aajSYisWvRg7YdJRYeB8\"\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nmodel = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-1219')\nresponse = model.generate_content(\"Explain AI to me like I'm a kid.\")\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:36:26.044548Z","iopub.execute_input":"2025-04-01T16:36:26.044889Z","iopub.status.idle":"2025-04-01T16:36:37.842803Z","shell.execute_reply.started":"2025-04-01T16:36:26.044866Z","shell.execute_reply":"2025-04-01T16:36:37.841817Z"}},"outputs":[{"name":"stdout","text":"Okay, imagine you have a really smart puppy, but instead of fur and wagging tails, it's made of computers! That's kind of like AI!\n\n**AI stands for Artificial Intelligence.**  That's a fancy way of saying \"making computers smart.\"\n\nThink about things you are good at:\n\n* **You can see and know** if something is a cat or a dog.\n* **You can understand** when someone talks to you.\n* **You can learn new things** and get better at them.\n* **You can make decisions**, like what game to play or what snack to eat.\n\n**AI is about teaching computers to do those things too!**\n\nWe want computers to:\n\n* **See things:** Like cameras that can tell if you're smiling or if a picture is of a dog.\n* **Understand words:** Like when you talk to Siri or Alexa and they understand what you're asking.\n* **Learn things:** Like a video game that gets harder as you get better at it, because it's learning how you play.\n* **Make decisions:**  Like a robot that can decide the best way to clean your room.\n\n**How do we teach computers to be smart?**\n\nWe give them lots and lots of examples!\n\nImagine you're teaching your puppy to sit. You show it how to sit, you say \"sit!\" and you give it a treat when it does it right.  After doing this many, many times, the puppy learns to sit when you say \"sit.\"\n\nIt's a bit like that with AI! We show computers tons of pictures of cats and dogs and tell them \"This is a cat\" and \"This is a dog.\"  Over time, the computer learns what makes a cat a cat and a dog a dog.  Then, when it sees a new picture, it can guess if it's a cat or a dog!\n\n**So, AI is like making computers clever by teaching them to see, understand, learn, and make decisions, just like you do!**\n\nIt's still a little bit like magic sometimes, but it's really just clever people writing instructions and giving computers lots of examples so they can become super smart helpers!\n\nDoes that make sense?  Do you have any questions?\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import google.generativeai as genai\n\n# Set up the API key\ngenai.configure(api_key=\"AIzaSyCKjXU-rGdoKM1aajSYisWvRg7YdJRYeB8\")\nfor m in genai.list_models():\n    print(m.name, \"supports generateContent\" if \"generateContent\" in m.supported_generation_methods else \"\")\n\n\n# Initialize the Gemini model\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\n# Generate content\nresponse = model.generate_content(\"Explain AI to me like I'm a kid.\")\n\n# Output the response\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:32:29.747870Z","iopub.execute_input":"2025-04-01T16:32:29.748367Z","iopub.status.idle":"2025-04-01T16:32:38.198467Z","shell.execute_reply.started":"2025-04-01T16:32:29.748334Z","shell.execute_reply":"2025-04-01T16:32:38.197309Z"}},"outputs":[{"name":"stdout","text":"models/chat-bison-001 \nmodels/text-bison-001 \nmodels/embedding-gecko-001 \nmodels/gemini-1.0-pro-vision-latest supports generateContent\nmodels/gemini-pro-vision supports generateContent\nmodels/gemini-1.5-pro-latest supports generateContent\nmodels/gemini-1.5-pro-001 supports generateContent\nmodels/gemini-1.5-pro-002 supports generateContent\nmodels/gemini-1.5-pro supports generateContent\nmodels/gemini-1.5-flash-latest supports generateContent\nmodels/gemini-1.5-flash-001 supports generateContent\nmodels/gemini-1.5-flash-001-tuning supports generateContent\nmodels/gemini-1.5-flash supports generateContent\nmodels/gemini-1.5-flash-002 supports generateContent\nmodels/gemini-1.5-flash-8b supports generateContent\nmodels/gemini-1.5-flash-8b-001 supports generateContent\nmodels/gemini-1.5-flash-8b-latest supports generateContent\nmodels/gemini-1.5-flash-8b-exp-0827 supports generateContent\nmodels/gemini-1.5-flash-8b-exp-0924 supports generateContent\nmodels/gemini-2.5-pro-exp-03-25 supports generateContent\nmodels/gemini-2.0-flash-exp supports generateContent\nmodels/gemini-2.0-flash supports generateContent\nmodels/gemini-2.0-flash-001 supports generateContent\nmodels/gemini-2.0-flash-exp-image-generation supports generateContent\nmodels/gemini-2.0-flash-lite-001 supports generateContent\nmodels/gemini-2.0-flash-lite supports generateContent\nmodels/gemini-2.0-flash-lite-preview-02-05 supports generateContent\nmodels/gemini-2.0-flash-lite-preview supports generateContent\nmodels/gemini-2.0-pro-exp supports generateContent\nmodels/gemini-2.0-pro-exp-02-05 supports generateContent\nmodels/gemini-exp-1206 supports generateContent\nmodels/gemini-2.0-flash-thinking-exp-01-21 supports generateContent\nmodels/gemini-2.0-flash-thinking-exp supports generateContent\nmodels/gemini-2.0-flash-thinking-exp-1219 supports generateContent\nmodels/learnlm-1.5-pro-experimental supports generateContent\nmodels/gemma-3-4b-it supports generateContent\nmodels/gemma-3-12b-it supports generateContent\nmodels/gemma-3-27b-it supports generateContent\nmodels/embedding-001 \nmodels/text-embedding-004 \nmodels/gemini-embedding-exp-03-07 \nmodels/gemini-embedding-exp \nmodels/aqa \nmodels/imagen-3.0-generate-002 \nImagine you have a super smart puppy!  Not a real puppy, but a pretend one inside a computer.  That puppy is kind of like **Artificial Intelligence**, or **AI** for short.\n\nAI is like teaching a computer to be a little bit like a human brain.  Humans are really good at thinking, learning new things, and figuring stuff out.  AI is trying to make computers do some of those same things.\n\nThink of it like this:\n\n* **Learning Tricks:**  You can teach a real puppy to sit, stay, and fetch, right?  AI is like teaching a computer to do \"tricks\" too, but the tricks are things like:\n    * **Recognizing pictures:**  Like showing the computer lots of pictures of cats and dogs, and then it learns to tell the difference between them!\n    * **Understanding words:**  Like asking the computer a question, and it can understand what you mean and try to answer!  Like Siri or Alexa!\n    * **Playing games:**  AI can learn to play games, even really complicated ones like chess or video games, and sometimes they can even get really, really good!\n    * **Helping you find things:**  When you search for something on the internet, AI helps the computer find the best websites for you!\n\n* **How does it learn?**  Imagine you show your puppy a treat every time it sits.  It learns that sitting means treat!  AI learns by being shown lots and lots and lots of examples.  Like showing it millions of pictures of cats to learn what a cat looks like.  It's like giving the computer lots of information and letting it figure out the patterns.\n\n* **Is it magic?** No, it's not magic!  It's clever computer programs written by smart people.  But it can seem a little bit like magic sometimes because it can do things that seem really smart!\n\n**So, AI is like a super smart computer program that can learn, think a little bit, and help us with lots of things!**  It's still learning and getting better all the time, just like you when you go to school!  It's used in lots of things you use every day, like your phone, video games, and even some toys!\n\nDoes that make sense?  Do you have any questions about your pretend puppy in the computer? üòä\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# Instantiate a model (use one that supports generateContent)\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\n# Generate a response\nresponse = model.generate_content(\"Explain AI to me like I'm a kid.\")\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:44:22.730369Z","iopub.execute_input":"2025-04-01T16:44:22.730712Z","iopub.status.idle":"2025-04-01T16:44:33.334782Z","shell.execute_reply.started":"2025-04-01T16:44:22.730685Z","shell.execute_reply":"2025-04-01T16:44:33.333649Z"}},"outputs":[{"name":"stdout","text":"Okay, imagine you have a really smart puppy, but instead of fur and paws, it's made of computers and wires! That puppy is kind of like **AI**.\n\n**AI** stands for **Artificial Intelligence**.  That's a big, fancy word, but it just means **making computers smart enough to do things that usually only smart people can do.**\n\nThink about these things that you are really good at:\n\n* **Learning new things:** Like when you learn to ride a bike or read a new word.\n* **Solving puzzles:** Like figuring out how to build a tower with blocks or finish a jigsaw puzzle.\n* **Understanding what people are saying:** Even when they talk fast or use silly words.\n* **Recognizing things:** Like knowing your toys, your friends, and your favorite ice cream flavor.\n\n**AI is about teaching computers to do those things too!**  We want computers to be able to:\n\n* **Learn from information:**  Imagine showing a computer lots and lots of pictures of cats.  AI can help the computer learn what a cat looks like so it can recognize a cat in a new picture.\n* **Solve problems:**  Like figuring out the best way to get to grandma's house using a map, or playing a game of checkers.\n* **Understand what we say and write:**  Like when you talk to Siri or Alexa on a phone or speaker, that's AI helping them understand you!\n* **Make decisions:**  Like a self-driving car deciding when to stop at a red light.\n\n**It's like giving computers brains, but brains made of code and electricity instead of mushy stuff!**\n\n**Here are some examples of AI you might already know:**\n\n* **Video games:**  Sometimes the characters you play against in video games are controlled by AI. They can learn how you play and get better at playing against you!\n* **Smartphones:**  When your phone suggests words as you type, or when it recognizes your face to unlock, that's AI working.\n* **Search engines:**  When you ask Google or YouTube a question, AI helps them understand what you're asking and find the best answers.\n* **Netflix or YouTube recommendations:**  When they suggest shows or videos you might like, that's AI figuring out what you enjoy based on what you've watched before.\n\n**AI isn't magic!**  It's made by people called **scientists and engineers** who write special instructions (like recipes for computers) to help them learn and be smart.\n\n**Is AI perfect?**  Nope!  Just like you are still learning and sometimes make mistakes, AI is still learning too.  Scientists are working hard to make AI even smarter and more helpful.\n\n**So, AI is like a super smart computer puppy that can learn, solve problems, and help us with all sorts of things!**  It's still new and growing, and it will be really cool to see all the amazing things AI will be able to do in the future!\n\nDo you have any questions about AI?  Maybe we can teach our computer puppy a new trick together! üòâ\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from pprint import pprint\n\n#for m in genai.list_models():\nfor model in genai.list_models():\n  if model.name == 'models/gemini-2.0-flash':\n    pprint(model)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:48:41.200598Z","iopub.execute_input":"2025-04-01T16:48:41.200939Z","iopub.status.idle":"2025-04-01T16:48:41.256182Z","shell.execute_reply.started":"2025-04-01T16:48:41.200913Z","shell.execute_reply":"2025-04-01T16:48:41.255106Z"}},"outputs":[{"name":"stdout","text":"Model(name='models/gemini-2.0-flash',\n      base_model_id='',\n      version='2.0',\n      display_name='Gemini 2.0 Flash',\n      description='Gemini 2.0 Flash',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=40)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from google.genai import types\nfrom google.generativeai.types import GenerationConfig\n\n\n# Configure the API key\ngenai.configure(api_key=\"AIzaSyCKjXU-rGdoKM1aajSYisWvRg7YdJRYeB8\")\n\n# Create a short response config (limit output to 200 tokens)\nshort_config = types.GenerationConfig(\n    max_output_tokens=200,\n    temperature=0.7\n)\n\n# Use a supported model (e.g., \"gemini-pro\")\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\n# Generate the content\nresponse = model.generate_content(\n    \"Write a 1000 word essay on the importance of olives in modern society.\",\n    # generation_config=short_config # this parameter is giving problem. May we have to get new version: pip install -U google-generativeai\n\n)\n\n# Print the output\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:40:53.289553Z","iopub.execute_input":"2025-04-01T17:40:53.289885Z","iopub.status.idle":"2025-04-01T17:41:10.838409Z","shell.execute_reply.started":"2025-04-01T17:40:53.289858Z","shell.execute_reply":"2025-04-01T17:41:10.837156Z"}},"outputs":[{"name":"stdout","text":"## The Enduring Green: Olives and Their Multifaceted Importance in Modern Society\n\nThe olive, a humble fruit born from gnarled branches and sun-drenched groves, carries within it a history as rich and textured as its oil.  For millennia, it has been a cornerstone of civilizations, particularly in the Mediterranean basin, weaving itself into the fabric of culture, cuisine, and economy. While often perceived as a traditional staple, olives are far from relics of the past. In modern society, their importance is not only sustained but amplified, extending far beyond mere culinary delight.  From their profound impact on global health and sustainable agriculture to their burgeoning role in the beauty and wellness industries, olives are a vital, multifaceted resource that continues to shape our world in profound and often understated ways.\n\nOne of the most significant contributions of olives to modern society is undeniably in the realm of health and nutrition.  The Mediterranean diet, with olive oil as its liquid gold heart, has become globally recognized as a paradigm of healthy eating.  Decades of scientific research have consistently lauded the health benefits of olive oil, primarily due to its high content of monounsaturated fatty acids, particularly oleic acid, and a wealth of antioxidants like polyphenols and vitamin E. These compounds work synergistically to combat inflammation, reduce the risk of cardiovascular diseases, lower bad cholesterol (LDL) while raising good cholesterol (HDL), and even offer protection against certain cancers.  In an era grappling with rising rates of chronic diseases linked to processed foods and sedentary lifestyles, the emphasis on olive oil as a healthy fat source is more crucial than ever. Modern dietary guidelines, from the World Health Organization to national health bodies, consistently recommend incorporating olive oil into daily diets, solidifying its importance in public health strategies aimed at promoting well-being and longevity.\n\nBeyond olive oil, table olives themselves offer a nutritional punch. Fermented olives are rich in probiotics, contributing to gut health and boosting the immune system, a factor increasingly appreciated in modern wellness trends. They are also a source of fiber, minerals like iron and copper, and vitamins.  In a society increasingly conscious of mindful eating and plant-based diets, olives provide a flavorful and versatile ingredient. They are no longer confined to antipasto platters; they are being incorporated into innovative dishes, from tapenades and salads to pizzas and even desserts, adding a salty, briny depth of flavor and nutritional value to modern cuisine.  The global fascination with fermentation and gut health further elevates the importance of olives, positioning them not just as a traditional food but as a functional food with tangible health benefits that resonate with contemporary health-conscious consumers.\n\nEconomically, the olive industry plays a substantial role on a global scale.  Olive cultivation and olive oil production are significant economic drivers, particularly for Mediterranean countries like Spain, Italy, Greece, and Tunisia, where olive groves are not just agricultural landscapes but integral parts of national identity and cultural heritage.  The olive oil industry provides livelihoods for millions, from farmers and harvesters to millers, bottlers, distributors, and retailers.  Modernization in olive farming techniques, while sometimes debated for its environmental impact, has also led to increased efficiency and production, allowing olive oil to reach wider global markets.  The demand for high-quality extra virgin olive oil, recognized for its superior flavor and health benefits, is constantly growing, driving innovation and investment in the sector.  Furthermore, the table olive industry, with its diverse varieties and preparations, is a significant export commodity for many olive-producing regions, contributing to international trade and economic growth.\n\nBeyond the traditional Mediterranean heartlands, olive cultivation is expanding globally.  Countries like Australia, the United States (California), and South Africa are increasingly investing in olive farming, driven by the growing global demand and the recognition of olives as a sustainable and resilient crop in certain climates.  This geographical diversification of olive production enhances food security and strengthens the global olive industry, making it less reliant on specific regions and vulnerable to localized disruptions.  The modernization of the olive industry, embracing technological advancements in harvesting, processing, and packaging, ensures its continued economic viability and its ability to meet the ever-increasing global demand.\n\nThe importance of olives extends beyond the tangible realms of health and economy into the less quantifiable, yet equally significant, sphere of culture and tradition.  For millennia, the olive tree has been a symbol of peace, wisdom, and prosperity.  The olive branch, famously carried by doves, is a universal emblem of peace, deeply ingrained in collective consciousness.  In mythology and religion, olives are revered; in ancient Greece, Athena gifted the olive tree to Athens, and in the Bible, the olive tree is mentioned numerous times, symbolizing abundance and divine favor.  This rich cultural heritage continues to resonate in modern society.  Olive groves are not just agricultural landscapes; they are living museums, imbued with history and tradition.  Olive oil production is often passed down through generations, representing family heritage and regional identity.  The act of sharing bread dipped in olive oil, or enjoying olives as part of a communal meal, remains a powerful social ritual, fostering connection and conviviality in an increasingly fast-paced and fragmented world.\n\nFurthermore, olives are increasingly finding their place in modern beauty and wellness trends.  Olive oil, rich in antioxidants and moisturizing properties, is a popular ingredient in skincare and haircare products.  From soaps and lotions to serums and hair masks, olive oil is celebrated for its natural emollient and rejuvenating qualities.  In a society increasingly seeking natural and sustainable beauty solutions, olive oil offers a gentle and effective alternative to synthetic chemicals.  The ‚Äúclean beauty‚Äù movement further elevates the importance of olive oil, recognizing its natural origin, minimal processing, and beneficial properties for skin and hair health.  This expands the reach of olives beyond the culinary and nutritional domains, positioning them as a versatile ingredient in the burgeoning wellness industry.\n\nFinally, and perhaps crucially for the future, the importance of olives in modern society is intertwined with the growing awareness of sustainable agriculture and environmental consciousness.  Olive trees are remarkably resilient and drought-tolerant, making them well-suited to arid and semi-arid climates, regions increasingly impacted by climate change.  Traditional olive farming practices, often characterized by low-input and rain-fed cultivation, are inherently sustainable.  While intensive olive farming, driven by market demands, can pose environmental challenges like water depletion and soil erosion, there is a growing movement towards sustainable olive cultivation.  Organic olive farming, agroforestry practices incorporating olive trees, and water-efficient irrigation techniques are gaining traction, aiming to minimize the environmental footprint of olive production.  In a world grappling with the urgent need for sustainable food systems, olives, when cultivated responsibly, offer a model for environmentally sound agriculture, providing food, economic opportunities, and cultural heritage while respecting ecological limits.\n\nIn conclusion, the importance of olives in modern society is far-reaching and multifaceted.  From their undeniable contribution to global health and nutrition, particularly through olive oil‚Äôs role in the Mediterranean diet, to their significant economic impact on producing regions and the expanding global market, olives are a vital resource.  Beyond the tangible benefits, their rich cultural heritage, symbolic significance, and burgeoning role in beauty and wellness industries further solidify their relevance.  Crucially, in an era demanding sustainable solutions, olives, when cultivated responsibly, represent a resilient and environmentally sound agricultural crop.  The enduring green of the olive tree, a symbol of peace and prosperity for millennia, continues to offer nourishment, economic opportunity, and cultural richness, firmly cementing its importance in the complex and evolving tapestry of modern society. As we navigate the challenges of the 21st century, the humble olive, with its multifaceted contributions, remains a vital and enduring resource, deserving of continued appreciation and sustainable cultivation for generations to come.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## Greedy Decoding\nGreedy decoding is a simple and fast method used in natural language generation (like in large language models or machine translation) to generate text one token at a time.\n\n### How It Works\nAt each step in generation:\n\nThe model predicts a probability distribution over the next possible tokens.\n\nGreedy decoding picks the token with the highest probability.\n\nThat token is added to the output sequence.\n\nRepeat until an end-of-sequence token is reached or a max length is hit.\n\nLike temperature, the top-P parameter is also used to control the diversity of the model's output.\n#### Top P\nTop-P defines the probability threshold that, once cumulatively exceeded, tokens stop being selected as candidates. A top-P of 0 is typically equivalent to greedy decoding, and a top-P of 1 typically selects every token in the model's vocabulary.\n\n#### Top K\nYou may also see top-K referenced in LLM literature. Top-K is not configurable in the Gemini 2.0 series of models, but can be changed in older models. Top-K is a positive integer that defines the number of most probable tokens from which to select the output token. A top-K of 1 selects a single token, performing greedy decoding.\n\nRun this example a number of times, change the settings and observe the change in output.","metadata":{}},{"cell_type":"code","source":"model_config = types.GenerateContentConfig(\n    # These are the default values for gemini-2.0-flash.\n    temperature=1.0,\n    top_p=0.95,\n)\n# Use a supported model (e.g., \"gemini-pro\")\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\nstory_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\nresponse = model.generate_content(\n    contents=story_prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:48:28.644232Z","iopub.execute_input":"2025-04-01T17:48:28.644602Z","iopub.status.idle":"2025-04-01T17:48:43.836580Z","shell.execute_reply.started":"2025-04-01T17:48:28.644575Z","shell.execute_reply":"2025-04-01T17:48:43.834908Z"}},"outputs":[{"name":"stdout","text":"Jasper, a ginger tabby of discerning taste and a rather magnificent tail, considered himself a connoisseur of sunbeams. His days were a carefully curated symphony of naps on the warmest spots of the Persian rug, demanding chin scratches from his human, Eleanor, and the occasional strategic swat at a dangling feather toy. Adventure?  Jasper scoffed inwardly. Adventure was for dogs, and squirrels ‚Äì creatures with questionable judgment.\n\nHowever, even the most steadfastly domestic cat can be swayed by the allure of the unknown.  It started with a moth. A large, clumsy luna moth, its wings the colour of pale jade, fluttering erratically against the windowpane. Jasper, roused from his afternoon slumber, watched with a flicker of predatory interest. He tapped a paw against the glass, then another, a low rumble of curiosity vibrating in his chest.\n\nThen, the impossible happened. Eleanor, bless her absentminded heart, left the back door ajar.  A sliver of the outside world, a tantalising crack in the wall of routine, beckoned. Jasper, usually content within the familiar scent of lavender and Eleanor's baking, felt a prickle of something unfamiliar ‚Äì an itch beneath his fur, a whisper in the breeze.  He hesitated.  The Persian rug was undeniably comfortable.  But the moth... and the open door‚Ä¶\n\nWith a decisive flick of his tail, Jasper slipped through the gap.\n\nThe world outside was a sensory explosion.  No longer muted by glass, sounds assaulted his sensitive ears: the chirping chorus of unseen birds, the rustle of leaves in a gentle breeze, the distant rumble of a car ‚Äì a monstrous, metallic beast he‚Äôd only ever glimpsed from the safety of the windowsill.  Smells swirled around him, a heady mix of damp earth, blooming roses (Eleanor‚Äôs pride and joy, usually forbidden territory), and something wild and untamed, like sunshine warmed on grass.\n\nJasper cautiously ventured into the garden.  The cool damp earth felt strange beneath his paws. He crept low to the ground, a ginger shadow moving through the emerald green of the lawn.  A butterfly, a flash of sapphire and gold, danced past his nose.  He twitched his whiskers, momentarily distracted, before remembering his mission ‚Äì or rather, his *lack* of mission, which was precisely the point.  He was simply exploring.\n\nHe discovered a hidden world beneath Eleanor‚Äôs rose bushes ‚Äì a cool, shadowy haven where the air smelled of rich soil and decaying leaves.  He stalked a fat bumblebee buzzing lazily around a lavender bush, his hunter instincts momentarily overriding his newfound sense of wonder.  (He didn't catch it, bumblebees were surprisingly nimble).\n\nHe climbed a tree, a scraggly apple tree in the corner of the garden, its bark rough and textured beneath his claws.  From his vantage point, the world stretched out further than he‚Äôd ever imagined.  He could see the rooftops of other houses, the glint of something silvery in the distance (a car? A river?  He wasn‚Äôt sure, but it was intriguing).  He felt a thrill, a tiny spark of wildness ignite within him.  This wasn't just his garden anymore. This was‚Ä¶ something bigger.\n\nHis adventure wasn‚Äôt without its perils.  A large, booming bark startled him from his treetop perch. A lumbering brown dog, all wagging tail and clumsy enthusiasm, bounded towards him, tongue lolling. Jasper, fur bristling, hissed and arched his back, a sudden surge of feline fear flooding him.  He scrambled higher into the branches, watching with wary green eyes as the dog sniffed at the base of the tree, then, thankfully, lumbered off in pursuit of a squirrel.\n\nShaken but undeterred, Jasper continued his exploration.  He discovered a patch of wild daisies, their white petals like tiny suns.  He tasted a blade of grass ‚Äì surprisingly bland.  He even, emboldened by his newfound bravery, ventured beyond the garden fence, into the narrow alleyway behind the houses.\n\nThe alley was a different world entirely.  It smelled of bins and something vaguely fishy.  He saw other cats here, sleek and streetwise, their eyes holding a knowing glint that Jasper, the pampered house cat, couldn't quite decipher.  They eyed him with suspicion, and he, sensing their territoriality, kept his distance.\n\nAs the sun began to dip below the horizon, painting the sky in hues of orange and rose, a pang of something unfamiliar tugged at Jasper‚Äôs whiskers.  It wasn't fear, not exactly.  It was‚Ä¶ longing.  Longing for the familiar warmth of the Persian rug, the gentle rhythm of Eleanor‚Äôs breathing, the comforting scent of home.\n\nHe turned and retraced his steps, the alleyway, the garden, the apple tree all now landmarks in his memory.  He found the back door still slightly ajar, a beacon in the gathering dusk. He slipped back inside, unnoticed, as if he'd never left.\n\nEleanor was in the kitchen, humming softly as she prepared dinner.  She didn‚Äôt even glance up as Jasper strolled back to his favourite sunbeam on the rug, settling down with a contented sigh.  He purred, a deep rumbling sound that filled the quiet house.\n\nHe was still Jasper, the ginger tabby of discerning taste, the connoisseur of sunbeams. But something had shifted.  The world outside the window wasn't just a hazy blur anymore.  He had smelled it, tasted it, felt it beneath his paws.  He had faced a barking dog, climbed a tree, and even ventured into the mysterious alley.  He had been, for a few glorious hours, an adventurer.\n\nAnd as he drifted off to sleep, dreaming of luna moths and hidden gardens, Jasper knew, with a quiet certainty, that this wouldn‚Äôt be his last adventure.  The world was far too interesting to be confined to a Persian rug, no matter how comfortable it was.  The ginger tabby, it seemed, had developed a taste for the unknown.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"*Zero Shot Prompt***","metadata":{}},{"cell_type":"code","source":"zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Her\" is a disturbing study revealing the direction\nhumanity is headed if AI is allowed to keep evolving,\nunchecked. I wish there were more movies like this masterpiece.\nSentiment: \"\"\"\n\n# Use a supported model (e.g., \"gemini-pro\")\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\n\nresponse = model.generate_content(\n    contents=zero_shot_prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:47:11.641275Z","iopub.execute_input":"2025-04-01T17:47:11.641659Z","iopub.status.idle":"2025-04-01T17:47:28.797740Z","shell.execute_reply.started":"2025-04-01T17:47:11.641632Z","shell.execute_reply":"2025-04-01T17:47:28.796498Z"}},"outputs":[{"name":"stdout","text":"POSITIVE\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\n# Use a supported model (e.g., \"gemini-pro\")\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\nresponse = model.generate_content(\n    config=types.GenerateContentConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ),\n    contents=zero_shot_prompt)\n\nprint(response.text)\n\n# I think the error indicates schema is nto yet supported or above is not in proper format.\n# You're trying to use a custom Python enum.Enum as a schema with response_schema in Gemini's generate_content() method, but that‚Äôs not currently supported in the way you're using it.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:53:32.364217Z","iopub.execute_input":"2025-04-01T17:53:32.364628Z","iopub.status.idle":"2025-04-01T17:53:32.381370Z","shell.execute_reply.started":"2025-04-01T17:53:32.364598Z","shell.execute_reply":"2025-04-01T17:53:32.380019Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-ff610f183a59>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-2.0-flash-thinking-exp-1219\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m response = model.generate_content(\n\u001b[0m\u001b[1;32m     12\u001b[0m     config=types.GenerateContentConfig(\n\u001b[1;32m     13\u001b[0m         \u001b[0mresponse_mime_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text/x.enum\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: GenerativeModel.generate_content() got an unexpected keyword argument 'config'"],"ename":"TypeError","evalue":"GenerativeModel.generate_content() got an unexpected keyword argument 'config'","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n```\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a large with cheese & pineapple\"\n# Use a supported model (e.g., \"gemini-pro\")\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\nresponse = model.generate_content(\n    # config=types.GenerateContentConfig(\n    #     temperature=0.1,\n    #     top_p=1,\n    #     max_output_tokens=250,\n    # ),\n    contents=[few_shot_prompt, customer_order])\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:03:46.941286Z","iopub.execute_input":"2025-04-01T18:03:46.941660Z","iopub.status.idle":"2025-04-01T18:03:48.634440Z","shell.execute_reply.started":"2025-04-01T18:03:46.941632Z","shell.execute_reply":"2025-04-01T18:03:48.632931Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"pineapple\"]\n}\n```\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"## Chain of Thought (CoT)¬∂\n\nDirect prompting on LLMs can return answers quickly and (in terms of output token usage) efficiently, but they can be prone to hallucination. The answer may \"look\" correct (in terms of language and syntax) but is incorrect in terms of factuality and reasoning.\n\nChain-of-Thought prompting is a technique where you instruct the model to output intermediate reasoning steps, and it typically gets better results, especially when combined with few-shot examples. It is worth noting that this technique doesn't completely eliminate hallucinations, and that it tends to cost more to run, due to the increased token count.\n\nModels like the Gemini family are trained to be \"chatty\" or \"thoughtful\" and will provide reasoning steps without prompting, so for this simple example you can ask the model to be more direct in the prompt to force a non-reasoning response. Try re-running this step if the model gets lucky and gets the answer correct on the first try.","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer directly.\"\"\"\n\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\nresponse = model.generate_content(\n    contents=prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:08:57.770600Z","iopub.execute_input":"2025-04-01T18:08:57.770969Z","iopub.status.idle":"2025-04-01T18:09:01.387962Z","shell.execute_reply.started":"2025-04-01T18:08:57.770944Z","shell.execute_reply":"2025-04-01T18:09:01.386835Z"}},"outputs":[{"name":"stdout","text":"When you were 4 years old, your partner was 3 times your age.\nPartner's age when you were 4 years old = 3 * 4 = 12 years old.\n\nThe age difference between you and your partner remains constant over time.\nAge difference = Partner's age when you were 4 - Your age when you were 4\nAge difference = 12 - 4 = 8 years.\n\nThis means your partner is always 8 years older than you.\n\nNow, you are 20 years old.\nTo find your partner's current age, add the age difference to your current age.\nPartner's current age = Your current age + Age difference\nPartner's current age = 20 + 8 = 28 years old.\n\nFinal Answer: The final answer is $\\boxed{28}$\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\nI am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n\nmodel = genai.GenerativeModel(model_name=\"gemini-2.0-flash-thinking-exp-1219\")\n\nresponse = model.generate_content(\n    contents=prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:11:20.730271Z","iopub.execute_input":"2025-04-01T18:11:20.730652Z","iopub.status.idle":"2025-04-01T18:11:24.235138Z","shell.execute_reply.started":"2025-04-01T18:11:20.730625Z","shell.execute_reply":"2025-04-01T18:11:24.233973Z"}},"outputs":[{"name":"stdout","text":"Here's a step-by-step thought process to solve this problem:\n\n1. **Identify the first key piece of information:** \"When I was 4 years old, my partner was 3 times my age.\"\n\n2. **Calculate the partner's age at that time:**  If my partner was 3 times my age when I was 4, then my partner's age was 3 * 4 = 12 years old.\n\n3. **Determine the age difference:** The age difference between two people remains constant over time.  To find the age difference, subtract my age from my partner's age at that time: 12 - 4 = 8 years. This means my partner is always 8 years older than me.\n\n4. **Identify the second key piece of information:** \"Now, I am 20 years old.\"\n\n5. **Calculate the partner's current age:** Since my partner is always 8 years older than me, and I am now 20, add the age difference to my current age to find my partner's current age: 20 + 8 = 28 years old.\n\n6. **Check the answer (optional but recommended):** Let's verify if the answer makes sense in the context of the original problem.\n    * When I was 4, my partner was 12 (3 times my age).\n    * The age difference is 12 - 4 = 8 years.\n    * Now I am 20, my partner is 28 (20 + 8 years difference).\n    The conditions are satisfied.\n\n**Answer:** My partner is 28 years old.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"**with the recent version of Gemini being used CoT doesn't bring much difference in the output**\nYes, \"gemini-2.0-flash-thinking-exp-1219\" is an experimental model within Google's Gemini 2.0 series, designed to enhance reasoning capabilities by explicitly showcasing its internal thought processes during response generation. This approach aims to improve performance and explainability in tasks requiring complex problem-solving.","metadata":{}},{"cell_type":"code","source":"import os\n\nfor root, dirs, files in os.walk(\"/kaggle/\"):\n    for file in files:\n        if file.endswith(\".ipynb\"):\n            print(os.path.join(root, file))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:43:56.354319Z","iopub.execute_input":"2025-04-01T18:43:56.354695Z","iopub.status.idle":"2025-04-01T18:43:56.361351Z","shell.execute_reply.started":"2025-04-01T18:43:56.354670Z","shell.execute_reply":"2025-04-01T18:43:56.360155Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"!git config --global user.email \"bmonobina@gmail\"\n!git config --global user.name \"monobinab-source\"\n\n# Clone your GitHub repo\n!git clone https://github.com/monobinab-source/genai.git\n\n# Copy the notebook to the repo directory\n!cp /kaggle/working/genai-prompting.ipynb genai/\n\n# Change to repo directory\n%cd genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:38:24.940405Z","iopub.execute_input":"2025-04-01T18:38:24.940786Z","iopub.status.idle":"2025-04-01T18:38:26.303152Z","shell.execute_reply.started":"2025-04-01T18:38:24.940760Z","shell.execute_reply":"2025-04-01T18:38:26.301657Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'genai'...\nremote: Enumerating objects: 3, done.\u001b[K\nremote: Counting objects: 100% (3/3), done.\u001b[K\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (3/3), done.\ncp: cannot stat '/kaggle/working/genai-prompting.ipynb': No such file or directory\n/kaggle/working/genai\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!git add genai-prompting.ipynb\n!git commit -m \"Add notebook from Kaggle\"\n!git push","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:39:00.179112Z","iopub.execute_input":"2025-04-01T18:39:00.179507Z","iopub.status.idle":"2025-04-01T18:42:49.340822Z","shell.execute_reply.started":"2025-04-01T18:39:00.179479Z","shell.execute_reply":"2025-04-01T18:42:49.339567Z"}},"outputs":[{"name":"stdout","text":"fatal: pathspec 'genai-prompting.ipynb' did not match any files\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\nUsername for 'https://github.com': ^C\n","output_type":"stream"}],"execution_count":50}]}