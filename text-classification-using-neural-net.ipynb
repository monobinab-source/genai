{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T22:43:23.880372Z","iopub.execute_input":"2025-04-01T22:43:23.880701Z","iopub.status.idle":"2025-04-01T22:43:23.886261Z","shell.execute_reply.started":"2025-04-01T22:43:23.880672Z","shell.execute_reply":"2025-04-01T22:43:23.885279Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp 2>/dev/null  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T22:43:15.845851Z","iopub.execute_input":"2025-04-01T22:43:15.846096Z","iopub.status.idle":"2025-04-01T22:43:23.879217Z","shell.execute_reply.started":"2025-04-01T22:43:15.846073Z","shell.execute_reply":"2025-04-01T22:43:23.877955Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T22:44:22.667660Z","iopub.execute_input":"2025-04-01T22:44:22.668131Z","iopub.status.idle":"2025-04-01T22:44:24.173650Z","shell.execute_reply.started":"2025-04-01T22:44:22.668078Z","shell.execute_reply":"2025-04-01T22:44:24.172729Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T22:53:25.699362Z","iopub.execute_input":"2025-04-01T22:53:25.700003Z","iopub.status.idle":"2025-04-01T22:53:26.267821Z","shell.execute_reply.started":"2025-04-01T22:53:25.699965Z","shell.execute_reply":"2025-04-01T22:53:26.266968Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups_train = fetch_20newsgroups(subset=\"train\")\nnewsgroups_test = fetch_20newsgroups(subset=\"test\")\n\n# View list of class names for dataset\nnewsgroups_train.target_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:05:43.523448Z","iopub.execute_input":"2025-04-01T23:05:43.523879Z","iopub.status.idle":"2025-04-01T23:05:53.837129Z","shell.execute_reply.started":"2025-04-01T23:05:43.523851Z","shell.execute_reply":"2025-04-01T23:05:53.836154Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Example record from train data","metadata":{}},{"cell_type":"code","source":"print(newsgroups_train.data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:06:54.891972Z","iopub.execute_input":"2025-04-01T23:06:54.892320Z","iopub.status.idle":"2025-04-01T23:06:54.898790Z","shell.execute_reply.started":"2025-04-01T23:06:54.892295Z","shell.execute_reply":"2025-04-01T23:06:54.897249Z"}},"outputs":[{"name":"stdout","text":"From: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n\n\n\n\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"#### Start by preprocessing the data for this tutorial in a Pandas dataframe. To remove any sensitive information like names and email addresses, you will take only the subject and body of each message. This is an optional step that transforms the input data into more generic text, rather than email posts, so that it will work in other contexts.","metadata":{}},{"cell_type":"code","source":"import email\nimport re\n\nimport pandas as pd\n\n\ndef preprocess_newsgroup_row(data):\n    # Extract only the subject and body\n    msg = email.message_from_string(data)\n    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n    # Strip any remaining email addresses\n    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n    # Truncate each entry to 5,000 characters\n    text = text[:5000]\n\n    return text\n\n\ndef preprocess_newsgroup_data(newsgroup_dataset):\n    # Put data points into dataframe\n    df = pd.DataFrame(\n        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n    )\n    # Clean up the text\n    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n    # Match label to target name index\n    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:10:41.380077Z","iopub.execute_input":"2025-04-01T23:10:41.380462Z","iopub.status.idle":"2025-04-01T23:10:41.386351Z","shell.execute_reply.started":"2025-04-01T23:10:41.380433Z","shell.execute_reply":"2025-04-01T23:10:41.385428Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Apply preprocessing function to training and test datasets\ndf_train = preprocess_newsgroup_data(newsgroups_train)\ndf_test = preprocess_newsgroup_data(newsgroups_test)\n\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:13:17.685691Z","iopub.execute_input":"2025-04-01T23:13:17.686181Z","iopub.status.idle":"2025-04-01T23:13:21.195796Z","shell.execute_reply.started":"2025-04-01T23:13:17.686152Z","shell.execute_reply":"2025-04-01T23:13:21.194870Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                Text  Label  \\\n0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n\n              Class Name  \n0              rec.autos  \n1  comp.sys.mac.hardware  \n2  comp.sys.mac.hardware  \n3          comp.graphics  \n4              sci.space  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n      <td>14</td>\n      <td>sci.space</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"#### Next, you will sample some of the data by taking 100 data points in the training dataset, and dropping a few of the categories to run through this tutorial. Choose the science categories to compare.","metadata":{}},{"cell_type":"code","source":"def sample_data(df, num_samples, classes_to_keep):\n    # Sample rows, selecting num_samples of each Label.\n    df = (\n        df.groupby(\"Label\")[df.columns]\n        .apply(lambda x: x.sample(num_samples))\n        .reset_index(drop=True)\n    )\n\n    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n\n    # We have fewer categories now, so re-calibrate the label encoding.\n    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:15:32.662347Z","iopub.execute_input":"2025-04-01T23:15:32.662799Z","iopub.status.idle":"2025-04-01T23:15:32.669357Z","shell.execute_reply.started":"2025-04-01T23:15:32.662770Z","shell.execute_reply":"2025-04-01T23:15:32.667889Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"TRAIN_NUM_SAMPLES = 100\nTEST_NUM_SAMPLES = 25\n# Class name should contain 'sci' to keep science categories.\n# Try different labels from the data - see newsgroups_train.target_names\nCLASSES_TO_KEEP = \"sci\"\n\ndf_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\ndf_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:16:26.446819Z","iopub.execute_input":"2025-04-01T23:16:26.447273Z","iopub.status.idle":"2025-04-01T23:16:26.495477Z","shell.execute_reply.started":"2025-04-01T23:16:26.447247Z","shell.execute_reply":"2025-04-01T23:16:26.494429Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_train.value_counts(\"Class Name\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:17:00.591324Z","iopub.execute_input":"2025-04-01T23:17:00.591736Z","iopub.status.idle":"2025-04-01T23:17:00.605771Z","shell.execute_reply.started":"2025-04-01T23:17:00.591708Z","shell.execute_reply":"2025-04-01T23:17:00.604476Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Class Name\nsci.crypt          100\nsci.electronics    100\nsci.med            100\nsci.space          100\nName: count, dtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"df_test.value_counts(\"Class Name\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:17:36.839548Z","iopub.execute_input":"2025-04-01T23:17:36.839941Z","iopub.status.idle":"2025-04-01T23:17:36.848601Z","shell.execute_reply.started":"2025-04-01T23:17:36.839908Z","shell.execute_reply":"2025-04-01T23:17:36.847722Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Class Name\nsci.crypt          25\nsci.electronics    25\nsci.med            25\nsci.space          25\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Create the embeddings¶\nIn this section, you will generate embeddings for each piece of text using the Gemini API embeddings endpoint. To learn more about embeddings, visit the embeddings guide.\n\nNOTE: Embeddings are computed one at a time, so large sample sizes can take a long time!","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\nimport tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\n# Add tqdm to Pandas...\ntqdmr.pandas()\n\n# ...But suppress the experimental warning.\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n@retry.Retry(predicate=is_retriable, timeout=300.0)\ndef embed_fn(text: str) -> list[float]:\n    # You will be performing classification, so set task_type accordingly.\n    response = client.models.embed_content(\n        model=\"models/text-embedding-004\",\n        contents=text,\n        config=types.EmbedContentConfig(\n            task_type=\"classification\",\n        ),\n    )\n\n    return response.embeddings[0].values\n\n\ndef create_embeddings(df):\n    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:19:25.060648Z","iopub.execute_input":"2025-04-01T23:19:25.061056Z","iopub.status.idle":"2025-04-01T23:19:25.287837Z","shell.execute_reply.started":"2025-04-01T23:19:25.061025Z","shell.execute_reply":"2025-04-01T23:19:25.286963Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df_train = create_embeddings(df_train)\ndf_test = create_embeddings(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:19:55.005782Z","iopub.execute_input":"2025-04-01T23:19:55.006431Z","iopub.status.idle":"2025-04-01T23:29:23.729009Z","shell.execute_reply.started":"2025-04-01T23:19:55.006402Z","shell.execute_reply":"2025-04-01T23:29:23.728104Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69786f9fea254e13b34a686aff27074a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ebd5b5238b498f8d9f4a98b96fc4c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:34:09.157407Z","iopub.execute_input":"2025-04-01T23:34:09.157950Z","iopub.status.idle":"2025-04-01T23:34:09.175916Z","shell.execute_reply.started":"2025-04-01T23:34:09.157913Z","shell.execute_reply":"2025-04-01T23:34:09.174898Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label Class Name  \\\n1100  Re: Do we need the clipper for cheap security?...     11  sci.crypt   \n1101  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n1102  Re: White House Public Encryption Management F...     11  sci.crypt   \n1103  Cryptography FAQ 05/10 - Product Ciphers\\n\\nAr...     11  sci.crypt   \n1104  Re: Key Registering Bodies\\n\\nIn article <>,  ...     11  sci.crypt   \n\n      Encoded Label                                         Embeddings  \n1100              0  [-0.0080845095, 0.034316238, -0.060537416, -0....  \n1101              0  [0.005113458, 0.020383235, -0.037115525, 0.047...  \n1102              0  [-0.0022490385, 0.0279606, -0.06618333, 0.0090...  \n1103              0  [-0.0030520577, 0.02042038, -0.05486683, 0.017...  \n1104              0  [-0.017480027, 0.02873167, -0.027140593, 0.029...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n      <th>Encoded Label</th>\n      <th>Embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1100</th>\n      <td>Re: Do we need the clipper for cheap security?...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.0080845095, 0.034316238, -0.060537416, -0....</td>\n    </tr>\n    <tr>\n      <th>1101</th>\n      <td>Re: Once tapped, your code is no good any more...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.005113458, 0.020383235, -0.037115525, 0.047...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>Re: White House Public Encryption Management F...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.0022490385, 0.0279606, -0.06618333, 0.0090...</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Cryptography FAQ 05/10 - Product Ciphers\\n\\nAr...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.0030520577, 0.02042038, -0.05486683, 0.017...</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Re: Key Registering Bodies\\n\\nIn article &lt;&gt;,  ...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.017480027, 0.02873167, -0.027140593, 0.029...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### Build a classification model¶\nHere you will define a simple model that accepts the raw embedding data as input, has one hidden layer, and an output layer specifying the class probabilities. The prediction will correspond to the probability of a piece of text being a particular class of news.\n\nWhen you run the model, Keras will take care of details like shuffling the data points, calculating metrics and other ML boilerplate.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras import layers\n\n\ndef build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n    return keras.Sequential(\n        [\n            layers.Input([input_size], name=\"embedding_inputs\"),\n            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n        ]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:35:10.997583Z","iopub.execute_input":"2025-04-01T23:35:10.998013Z","iopub.status.idle":"2025-04-01T23:35:24.484092Z","shell.execute_reply.started":"2025-04-01T23:35:10.997981Z","shell.execute_reply":"2025-04-01T23:35:24.483083Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Derive the embedding size from observing the data. The embedding size can also be specified\n# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\nembedding_size = len(df_train[\"Embeddings\"].iloc[0]) \n\nclassifier = build_classification_model(\n    embedding_size, len(df_train[\"Class Name\"].unique()) # input size is embedding size 769 and output size is number of class labels\n)\nclassifier.summary()\n\nclassifier.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=keras.optimizers.Adam(learning_rate=0.001), # optimizer=keras.optimizers.Adam(...) ← this is where you choose how to apply gradient descent.Adam is an advanced optimizer based on gradient descent, but with adaptive learning rates and momentum.\n    metrics=[\"accuracy\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:36:44.095505Z","iopub.execute_input":"2025-04-01T23:36:44.096609Z","iopub.status.idle":"2025-04-01T23:36:44.235972Z","shell.execute_reply.started":"2025-04-01T23:36:44.096560Z","shell.execute_reply":"2025-04-01T23:36:44.234976Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ hidden (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │         \u001b[38;5;34m590,592\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output_probs (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m3,076\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ output_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,076</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"### Train the model \n\nWhat is an Epoch?\nAn epoch is one full pass through your entire training dataset.\n\nIf you have 10,000 training samples, and you train for 10 epochs...\n\nThat means your model will see all 10,000 samples 10 times (in batches).\n\nMore epochs = more learning... but too many can cause overfitting (memorizing the data).\n\n#### Explanation of All Parameters\nParameter\tWhat It Means\n\nx\tThe training input data (e.g., embeddings or features)\n\ny\tThe training labels (e.g., sentiment: 0, 1, 2)\n\nvalidation_data\tA tuple (x_val, y_val) for checking how well the model performs on unseen data after each epoch\n\ncallbacks\tList of things to run during training — like early_stop to stop training when validation stops improving\n\nbatch_size\tNumber of training samples processed before updating weights\n\nepochs\tHow many times to run through the entire training dataset\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\nNUM_EPOCHS = 20\nBATCH_SIZE = 32\n\n# Split the x and y components of the train and validation subsets.\ny_train = df_train[\"Encoded Label\"]\nx_train = np.stack(df_train[\"Embeddings\"])\ny_val = df_test[\"Encoded Label\"]\nx_val = np.stack(df_test[\"Embeddings\"])\n\n# Specify that it's OK to stop early if accuracy stabilises.\nearly_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n\n# Train the model for the desired number of epochs.\nhistory = classifier.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_val, y_val),\n    callbacks=[early_stop],\n    batch_size=BATCH_SIZE,\n    epochs=NUM_EPOCHS,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:38:40.708385Z","iopub.execute_input":"2025-04-01T23:38:40.708837Z","iopub.status.idle":"2025-04-01T23:38:44.488562Z","shell.execute_reply.started":"2025-04-01T23:38:40.708803Z","shell.execute_reply":"2025-04-01T23:38:44.487633Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3266 - loss: 1.3664 - val_accuracy: 0.4800 - val_loss: 1.2917\nEpoch 2/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 1.2274 - val_accuracy: 0.7300 - val_loss: 1.1609\nEpoch 3/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7828 - loss: 1.0687 - val_accuracy: 0.8000 - val_loss: 1.0274\nEpoch 4/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8795 - loss: 0.8683 - val_accuracy: 0.8100 - val_loss: 0.8552\nEpoch 5/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9181 - loss: 0.6680 - val_accuracy: 0.8500 - val_loss: 0.7379\nEpoch 6/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.5468 - val_accuracy: 0.8700 - val_loss: 0.5943\nEpoch 7/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9520 - loss: 0.4124 - val_accuracy: 0.9100 - val_loss: 0.4942\nEpoch 8/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.3128 - val_accuracy: 0.9100 - val_loss: 0.4509\nEpoch 9/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9720 - loss: 0.2703 - val_accuracy: 0.9200 - val_loss: 0.3842\nEpoch 10/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9664 - loss: 0.2037 - val_accuracy: 0.9300 - val_loss: 0.3502\nEpoch 11/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.1719 - val_accuracy: 0.9400 - val_loss: 0.3169\nEpoch 12/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.1373 - val_accuracy: 0.9300 - val_loss: 0.3119\nEpoch 13/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.1378 - val_accuracy: 0.9600 - val_loss: 0.2839\nEpoch 14/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.1233 - val_accuracy: 0.9300 - val_loss: 0.2601\nEpoch 15/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.1003 - val_accuracy: 0.9300 - val_loss: 0.2646\nEpoch 16/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0886 - val_accuracy: 0.9300 - val_loss: 0.2432\nEpoch 17/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0860 - val_accuracy: 0.9300 - val_loss: 0.2667\nEpoch 18/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0766 - val_accuracy: 0.9400 - val_loss: 0.2397\nEpoch 19/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0742 - val_accuracy: 0.9300 - val_loss: 0.2193\nEpoch 20/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0684 - val_accuracy: 0.9300 - val_loss: 0.2082\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"classifier.evaluate(x=x_val, y=y_val, return_dict=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:40:50.429482Z","iopub.execute_input":"2025-04-01T23:40:50.429866Z","iopub.status.idle":"2025-04-01T23:40:50.526501Z","shell.execute_reply.started":"2025-04-01T23:40:50.429842Z","shell.execute_reply":"2025-04-01T23:40:50.525355Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2075 \n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.9300000071525574, 'loss': 0.20822980999946594}"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"### Make Prediction to new text","metadata":{}},{"cell_type":"code","source":"def make_prediction(text: str) -> list[float]:\n    \"\"\"Infer categories from the provided text.\"\"\"\n    # Remember that the model takes embeddings as input, so calculate them first.\n    embedded = embed_fn(new_text)\n\n    # And recall that the input must be batched, so here they are wrapped as a\n    # list to provide a batch of 1.\n    inp = np.array([embedded])\n\n    # And un-batched here.\n    [result] = classifier.predict(inp)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:42:41.444105Z","iopub.execute_input":"2025-04-01T23:42:41.444449Z","iopub.status.idle":"2025-04-01T23:42:41.449867Z","shell.execute_reply.started":"2025-04-01T23:42:41.444426Z","shell.execute_reply":"2025-04-01T23:42:41.448704Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"#### Here is the text to classify into probable categories","metadata":{}},{"cell_type":"code","source":"# This example avoids any space-specific terminology to see if the model avoids\n# biases towards specific jargon.\nnew_text = \"\"\"\nFirst-timer looking to get out of here.\n\nHi, I'm writing about my interest in travelling to the outer limits!\n\nWhat kind of craft can I buy? What is easiest to access from this 3rd rock?\n\nLet me know how to do that please.\n\"\"\"\n\nresult = make_prediction(new_text)\n\nfor idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n    print(f\"{category}: {result[idx] * 100:0.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T23:43:03.347924Z","iopub.execute_input":"2025-04-01T23:43:03.348275Z","iopub.status.idle":"2025-04-01T23:43:03.710554Z","shell.execute_reply.started":"2025-04-01T23:43:03.348244Z","shell.execute_reply":"2025-04-01T23:43:03.709663Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\nsci.crypt: 0.04%\nsci.electronics: 0.35%\nsci.med: 0.02%\nsci.space: 99.59%\n","output_type":"stream"}],"execution_count":22}]}